---
title: A Structured Self-attentive Sentence Embedding
authors:
- Zhouhan Lin
- Minwei Feng
- C. D. Santos
- Mo Yu
- Bing Xiang
- Bowen Zhou
- Yoshua Bengio
fieldsOfStudy:
- Computer Science
meta_key: 2017-a-structured-self-attentive-sentence-embedding
numCitedBy: 1516
reading_status: TBD
ref_count: 44
tags:
- gen-from-ref
- other-default
- paper
urls:
- https://www.semanticscholar.org/paper/A-Structured-Self-attentive-Sentence-Embedding-Lin-Feng/204a4a70428f3938d2c538a4d74c7ae0416306d8?sort=total-citations
venue: ICLR
year: 2017
---

[semanticscholar url](https://www.semanticscholar.org/paper/A-Structured-Self-attentive-Sentence-Embedding-Lin-Feng/204a4a70428f3938d2c538a4d74c7ae0416306d8?sort=total-citations)

# A Structured Self-attentive Sentence Embedding

## Abstract

This paper proposes a new model for extracting an interpretable sentence embedding by introducing self-attention. Instead of using a vector, we use a 2-D matrix to represent the embedding, with each row of the matrix attending on a different part of the sentence. We also propose a self-attention mechanism and a special regularization term for the model. As a side effect, the embedding comes with an easy way of visualizing what specific parts of the sentence are encoded into the embedding. We evaluate our model on 3 different tasks: author profiling, sentiment classification, and textual entailment. Results show that our model yields a significant performance gain compared to other sentence embedding methods in all of the 3 tasks.

## Paper References

1. [Skip-Thought Vectors](2015-skip-thought-vectors.md)
2. Deep Sentence Embedding Using Long Short-Term Memory Networks - Analysis and Application to Information Retrieval
3. Learning Natural Language Inference using Bidirectional LSTM model and Inner-Attention
4. [A Convolutional Neural Network for Modelling Sentences](2014-a-convolutional-neural-network-for-modelling-sentences.md)
5. Discriminative Neural Sentence Modeling by Tree-Based Convolution
6. [Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions](2011-semi-supervised-recursive-autoencoders-for-predicting-sentiment-distributions.md)
7. Not All Contexts Are Created Equal - Better Word Representations with Variable Attention
8. [Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank](2013-recursive-deep-models-for-semantic-compositionality-over-a-sentiment-treebank.md)
9. [GloVe - Global Vectors for Word Representation](2014-glove-global-vectors-for-word-representation.md)
10. [Order-Embeddings of Images and Language](2016-order-embeddings-of-images-and-language.md)
11. Dependency-based Convolutional Neural Networks for Sentence Embedding
12. [Distributed Representations of Sentences and Documents](2014-distributed-representations-of-sentences-and-documents.md)
13. Deep Convolutional Neural Networks for Sentiment Analysis of Short Texts
14. Attentive Pooling Networks
15. Neural Semantic Encoders
16. [Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks](2015-improved-semantic-representations-from-tree-structured-long-short-term-memory-networks.md)
17. A Decomposable Attention Model for Natural Language Inference
18. A Batch-Normalized Recurrent Network for Sentiment Classification
19. Improved Representation Learning for Question Answer Matching
20. Natural Language Inference by Tree-Based Convolution and Heuristic Matching
21. [Efficient Estimation of Word Representations in Vector Space](2013-efficient-estimation-of-word-representations-in-vector-space.md)
22. [Long Short-Term Memory-Networks for Machine Reading](2016-long-short-term-memory-networks-for-machine-reading.md)
23. Sequential Short-Text Classification with Recurrent and Convolutional Neural Networks
24. Neural Tree Indexers for Text Understanding
25. [A large annotated corpus for learning natural language inference](2015-a-large-annotated-corpus-for-learning-natural-language-inference.md)
26. Dataset and Neural Recurrent Sequence Labeling Model for Open-Domain Factoid Question Answering
27. A Neural Probabilistic Language Model
28. Applying deep learning to answer selection - A study and an open task
29. [Learning Distributed Representations of Sentences from Unlabelled Data](2016-learning-distributed-representations-of-sentences-from-unlabelled-data.md)
30. [Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling](2014-empirical-evaluation-of-gated-recurrent-neural-networks-on-sequence-modeling.md)
31. [Long Short-Term Memory](1997-long-short-term-memory.md)
32. [Theano - A Python framework for fast computation of mathematical expressions](2016-theano-a-python-framework-for-fast-computation-of-mathematical-expressions.md)
33. [Published as a conference paper at ICLR 2018 S IMULATING A CTION D YNAMICS WITH N EURAL P ROCESS N ETWORKS](2018-published-as-a-conference-paper-at-iclr-2018-s-imulating-a-ction-d-ynamics-with-n-eural-p-rocess-n-etworks.md)
34. Learning to Relate Images
35. [IEEE Transactions on Pattern Analysis and Machine Intelligence Publication Information](2022-ieee-transactions-on-pattern-analysis-and-machine-intelligence-publication-information.md)
36. A Fast Unified Model for Parsing and Sentence Understanding
37. Convolutional Neural Network for Paraphrase Identification
38. [Convolutional Neural Networks for Sentence Classification](2014-convolutional-neural-networks-for-sentence-classification.md)
