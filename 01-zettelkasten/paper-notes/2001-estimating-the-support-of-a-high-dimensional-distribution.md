---
title: Estimating the Support of a High-Dimensional Distribution
authors:
- B. Schölkopf
- John C. Platt
- J. Shawe-Taylor
- Alex Smola
- R. C. Williamson
fieldsOfStudy:
- Computer Science
meta_key: 2001-estimating-the-support-of-a-high-dimensional-distribution
numCitedBy: 4715
reading_status: TBD
ref_count: 78
tags:
- gen-from-ref
- other-default
- paper
urls:
- https://www.semanticscholar.org/paper/Estimating-the-Support-of-a-High-Dimensional-Schölkopf-Platt/9cc912ae25797e5f7c0d73300d3968ad8339b411?sort=total-citations
venue: Neural Computation
year: 2001
---

[semanticscholar url](https://www.semanticscholar.org/paper/Estimating-the-Support-of-a-High-Dimensional-Schölkopf-Platt/9cc912ae25797e5f7c0d73300d3968ad8339b411?sort=total-citations)

# Estimating the Support of a High-Dimensional Distribution

## Abstract

Suppose you are given some data set drawn from an underlying probability distribution P and you want to estimate a simple subset S of input space such that the probability that a test point drawn from P lies outside of S equals some a priori specified value between 0 and 1. We propose a method to approach this problem by trying to estimate a function f that is positive on S and negative on the complement. The functional form of f is given by a kernel expansion in terms of a potentially small subset of the training data; it is regularized by controlling the length of the weight vector in an associated feature space. The expansion coefficients are found by solving a quadratic programming problem, which we do by carrying out sequential optimization over pairs of input patterns. We also provide a theoretical analysis of the statistical performance of our algorithm. The algorithm is a natural extension of the support vector algorithm to the case of unlabeled data.

## Paper References

1. On nonparametric estimation of density level sets
2. Generalization Performance of Classifiers in Terms of Observed Covering Numbers
3. Detection of Abnormal Behavior Via Nonparametric Estimation of the Support
4. Learning Distributions by Their Density Levels - A Paradigm for Learning without a Teacher
5. Structural Risk Minimization Over Data-Dependent Hierarchies
6. Margin Distribution Bounds on Generalization
7. Entropy Numbers, Operators and Support Vector Kernels
8. Generalization performance of regularization networks and support vector machines via entropy numbers of compact operators
9. Kernel method for percentile feature extraction
10. Support vector learning
11. Extracting Support Data for a Given Task
12. Probability Density Estimation from Optimally Condensed Data Samples
13. Density estimation under qualative assumptions inhigher dimensions
14. An Equivalence Between Sparse Approximation and Support Vector Machines
15. On the generalization of soft margin algorithms
16. Entropy Numbers of Linear Function Classes
17. Making a multilayered perceptron network say - don't know when it should
18. An Iterative Method for Estimating a Multivariate Mode and Isopleth
19. Fast training of support vector machines using sequential minimal optimization, advances in kernel methods
20. Measuring Mass Concentrations and Estimating Density Contour Clusters-An Excess Mass Approach
21. Making large-scale support vector machine learning practical
22. New Support Vector Algorithms
23. Regularized Principal Manifolds
24. Advances in kernel methods - support vector learning
25. The excess-mass ellipsoid
26. Classification in a normalized feature space using support vector machines
27. Estimation of a Convex Density Contour in Two Dimensions
28. Minimax theory of image reconstruction
29. [Statistical learning theory](1998-statistical-learning-theory.md)
30. Networks for approximation and learning
31. [An introduction to kernel-based learning algorithms](2001-an-introduction-to-kernel-based-learning-algorithms.md)
32. Novelty detection for the identification of masses in mammograms
33. Minimum volume sets and generalized quantile processes
34. The connection between regularization operators and support vector kernels
35. Generalized quantile processes
36. On Pattern Analysis in the Non‐Convex Case
37. [Elements of Information Theory](1991-elements-of-information-theory.md)
38. Applicational aspects of support vector machines
39. Kernel Principal Component Analysis
40. Supervised-PCA and SVM classifiers for object detection in infrared images
41. Improvements to Platt's SMO Algorithm for SVM Classifier Design
42. Four-legged Walking Gait Control Using a Neuromorphic Chip Interfaced to a Support Vector Learning Algorithm
43. [The Nature of Statistical Learning Theory](2000-the-nature-of-statistical-learning-theory.md)
44. Improving the manufacturability of electronic designs
45. Support Vector Novelty Detection Applied to Jet Engine Vibration Spectra
46. NONLINEAR PROGRAMMING
47. Fast training of svms using sequential minimal optimization
48. Making large scale SVM learning practical
49. Annales de l'Institut Henri Poincaré. Section B, Calcul des probabilités et statistique
50. Bounds on Error Expectation for SVM
51. A plug-in approach to support estimation
52. Bounds on error expectation for SVM
53. MiniMax Methods for Image Reconstruction
54. Pattern recognition using generalized portrait method
55. Advances in Kernel Methods - Support Vector Learning
56. Single-class Support Vector Machines
57. A Theory of Pattern Recognition
58. [A training algorithm for optimal margin classifiers](1992-a-training-algorithm-for-optimal-margin-classifiers.md)
