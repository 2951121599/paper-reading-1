---
title: Recommendations with Negative Feedback via Pairwise Deep Reinforcement Learning
authors:
- Xiangyu Zhao
- L. Zhang
- Zhuoye Ding
- Long Xia
- Jiliang Tang
- Dawei Yin
fieldsOfStudy:
- Computer Science
meta_key: 2018-recommendations-with-negative-feedback-via-pairwise-deep-reinforcement-learning
numCitedBy: 208
reading_status: TBD
ref_count: 55
tags:
- gen-from-ref
- other-default
- paper
urls:
- https://www.semanticscholar.org/paper/Recommendations-with-Negative-Feedback-via-Pairwise-Zhao-Zhang/ef08ad10d257fcf5043d27d7225d6ec14a677a84?sort=total-citations
venue: KDD
year: 2018
---

[semanticscholar url](https://www.semanticscholar.org/paper/Recommendations-with-Negative-Feedback-via-Pairwise-Zhao-Zhang/ef08ad10d257fcf5043d27d7225d6ec14a677a84?sort=total-citations)

# Recommendations with Negative Feedback via Pairwise Deep Reinforcement Learning

## Abstract

Recommender systems play a crucial role in mitigating the problem of information overload by suggesting users' personalized items or services. The vast majority of traditional recommender systems consider the recommendation procedure as a static process and make recommendations following a fixed strategy. In this paper, we propose a novel recommender system with the capability of continuously improving its strategies during the interactions with users. We model the sequential interactions between users and a recommender system as a Markov Decision Process (MDP) and leverage Reinforcement Learning (RL) to automatically learn the optimal strategies via recommending trial-and-error items and receiving reinforcements of these items from users' feedback. Users' feedback can be positive and negative and both types of feedback have great potentials to boost recommendations. However, the number of negative feedback is much larger than that of positive one; thus incorporating them simultaneously is challenging since positive feedback could be buried by negative one. In this paper, we develop a novel approach to incorporate them into the proposed deep recommender system (DEERS) framework. The experimental results based on real-world e-commerce data demonstrate the effectiveness of the proposed framework. Further experiments have been conducted to understand the importance of both positive and negative feedback in recommendations.

## Paper References

1. Deep Reinforcement Learning for List-wise Recommendations
2. Deep reinforcement learning for page-wise recommendations
3. Returning is Believing - Optimizing Long-term User Engagement in Recommender Systems
4. Learning and adaptivity in interactive recommender systems
5. Deep Learning Based Recommender System
6. Improving recommender systems with adaptive conversational strategies
7. Usage-based web recommendations - a reinforcement learning approach
8. A hybrid web recommender system based on Q-learning
9. Session-based Recommendations with Recurrent Neural Networks
10. Recommender systems
11. Personalized Deep Learning for Tag Recommendation
12. An MDP-Based Recommender System
13. Recommender Systems
14. Hybrid Recommender Systems - Survey and Experiments
15. Deep Reinforcement Learning with Attention for Slate Markov Decision Processes with High-Dimensional States and Actions
16. Empirical Analysis of Predictive Algorithms for Collaborative Filtering
17. A user browsing model to predict search engine click data from past observations.
18. [Amazon.com Recommendations - Item-to-Item Collaborative Filtering](2003-amazon-com-recommendations-item-to-item-collaborative-filtering.md)
19. Content-based book recommending using learning for text categorization
20. Factorization Machines
21. Cumulated gain-based evaluation of IR techniques
22. Introduction to Recommender Systems Handbook
23. Reinforcement learning for robots using neural networks
24. [Playing Atari with Deep Reinforcement Learning](2013-playing-atari-with-deep-reinforcement-learning.md)
25. Off-Policy Actor-Critic
26. User performance versus precision measures for simple search tasks
27. Incremental Methods for Computing Bounds in Partially Observable Markov Decision Processes
28. A Sparse Sampling Algorithm for Near-Optimal Planning in Large Markov Decision Processes
29. Prioritized Sweeping - Reinforcement Learning with Less Data and Less Time
30. PEGASUS - A policy search method for large MDPs and POMDPs
31. User Modeling and User-Adapted Interaction
32. VDCBPI - an Approximate Scalable Algorithm for Large POMDPs
33. Dynamic Programming
34. Knowledge Based Systems
35. What is dynamic programming?
36. Personal recommendation using deep recurrent neural networks in NetEase
37. Neural Word Embedding as Implicit Matrix Factorization
